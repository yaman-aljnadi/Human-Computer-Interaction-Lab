{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e08641cc",
   "metadata": {},
   "source": [
    "# Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "455d0064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OD>': {'bboxes': [[175.6160125732422, 0.7199999690055847, 797.1840209960938, 478.3199768066406]], 'labels': ['Kermit the Frog in The Muppets']}}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM \n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Florence-2-large\", \n",
    "    torch_dtype=torch_dtype, \n",
    "    trust_remote_code=True,\n",
    "    attn_implementation=\"eager\"\n",
    ").to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/Florence-2-large\", trust_remote_code=True)\n",
    "\n",
    "url = \"../Pictures_&_Videos/Testing_Pictures/kermit.jpg\" \n",
    "try:\n",
    "    image = Image.open(url).convert(\"RGB\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"Image not found at {url}. Please check the path.\")\n",
    "\n",
    "\n",
    "\n",
    "prompt = \"\"\n",
    "inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(device, torch_dtype)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    pixel_values=inputs[\"pixel_values\"],\n",
    "    max_new_tokens=4096,\n",
    "    num_beams=3,\n",
    "    do_sample=False,\n",
    "    use_cache=False  \n",
    ")\n",
    "\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "parsed_answer = processor.post_process_generation(generated_text, task=\"<OD>\", image_size=(image.width, image.height))\n",
    "\n",
    "print(parsed_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efd2222",
   "metadata": {},
   "source": [
    "# Live Video Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6106f42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Webcam opened. Press 'q' to quit.\n",
      "\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch with phone in living room', 'woman on video call with phone and glasses']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch in living room with kitchen in background']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch with phone in living room', 'woman on phone in kitchen with kitchen cabinets in background']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch with phone in living room', 'woman on phone in kitchen with kitchen cabinets in background']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch with phone in living room', 'woman on phone in kitchen with wooden cabinets and countertop']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch with phone in living room', 'woman on sofa with phone and coffee cup', 'woman on bed with phone on couch in living area', 'woman in living-room with phone']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch with phone in living room', 'woman on reclining sofa with remote control']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch with phone in living room', 'woman on video call with phone and laptop']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch with phone in living room', 'woman on video call with phone and laptop']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch with phone in living room', 'woman on phone in kitchen with wooden cabinets and countertop']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch with phone in living room', 'woman on phone in kitchen with kitchen cabinets in background']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch with phone in living room', 'woman on video call with phone and laptop']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch with phone in living room', 'woman on phone in kitchen with kitchen cabinets in background']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch with phone in living room', 'woman on phone in kitchen with kitchen cabinets in background']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch with phone in living room', 'woman on video call with phone on couch']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch with phone in living room', 'woman on phone in kitchen with kitchen cabinets in background']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch with phone in living room', 'woman on phone in kitchen with kitchen cabinets in background']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch with cell phone in living room', 'woman on video call with phone in hand']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch in living room with kitchen in background']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman sitting on couch in living room with armchair and coffee table', 'woman in blue polo shirt on couch with coffee table in background']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch in living room with blue couch and white walls', 'woman in blue shirt sitting on couch with arms crossed and looking at camera']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch in living room', 'woman in blue shirt sitting on couch with arms crossed and looking at camera']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch in living room with kitchen in background']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch in living room with laptop and remote control', 'woman on sofa with laptop on couch', 'woman in blue shirt sitting on couch with arms crossed and looking at camera']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch in living room with blue and white patterned couch']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch in living room with blue shirt and glasses', 'woman on video call with blue polo shirt and black pants']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['woman on couch in living room with kitchen in background']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['person']\n",
      "\n",
      "--- NEW FRAME ---\n",
      "[]\n",
      "\n",
      "--- NEW FRAME ---\n",
      "['man in red and black plaid shirt on couch']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Florence-2-large\",\n",
    "    torch_dtype=torch_dtype,\n",
    "    trust_remote_code=True,\n",
    "    attn_implementation=\"eager\"\n",
    ").to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    \"microsoft/Florence-2-large\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # 0 = default webcam\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"❌ Cannot open webcam.\")\n",
    "\n",
    "print(\"✅ Webcam opened. Press 'q' to quit.\\n\")\n",
    "\n",
    "\n",
    "prompt = \"\"  \n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Live Camera Feed\", frame)\n",
    "\n",
    "    pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    \n",
    "    inputs = processor(\n",
    "        text=prompt,\n",
    "        images=pil_image,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device, torch_dtype)\n",
    "\n",
    "    \n",
    "    generated_ids = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        pixel_values=inputs[\"pixel_values\"],\n",
    "        max_new_tokens=512,\n",
    "        num_beams=3,\n",
    "        do_sample=False,\n",
    "        use_cache=False\n",
    "    )\n",
    "\n",
    "    \n",
    "    generated_text = processor.batch_decode(\n",
    "        generated_ids, \n",
    "        skip_special_tokens=False\n",
    "    )[0]\n",
    "\n",
    "    parsed_answer = processor.post_process_generation(\n",
    "        generated_text,\n",
    "        task=\"<OD>\",   \n",
    "        image_size=(pil_image.width, pil_image.height)\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- NEW FRAME ---\")\n",
    "    print(parsed_answer['<OD>']['labels'])\n",
    "\n",
    "    # Quit with q\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be8ccc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HCI_LAB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
